# LLM-Enhanced-Text-Conditioning-for-Inversion-based-Style-Transfer
Style transfer is a deep learning technique that
synthesizes an image by blending the content of one image
with the style of another. Recent advancements, particularly in
diffusion-based methods, have enhanced the ability to capture
intricate details in style and structure. The Inversion-based Style
Transfer (InST) approach uses diffusion models and textual
inversion to transfer detailed stylistic elements, such as brushstrokes and color schemes, from a reference painting to a natural
image while preserving content integrity. However, InST faces
challenges in style representation quality, especially when using
textual encodings. In this work, we introduce an improvement
to InST by incorporating ShareGPT-4V LLaVA(Large Language
and Vision Assistant) model to generate refined style descriptions
directly from images, enabling enhanced prompt optimization.
This modification allows the model to better encode the unique
characteristics of style images, producing more stylistically accurate and visually compelling results. Our experiments show that
this approach reduces content deviation and improves the fidelity
of style transfer, yielding higher-quality images.
